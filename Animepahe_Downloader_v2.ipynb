{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Animepahe Downloader v2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNgjreadMDHUZHW91LSYxf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamimmahmud0/animpahe_downloader/blob/master/Animepahe_Downloader_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzRw_Q4BgAGw",
        "colab_type": "text"
      },
      "source": [
        "# Form\n",
        "Fill up the form:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep4-DtQoIdui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "URL = 'https://animepahe.com/anime/453da1c1-e3fe-7f1b-7655-4ee278f5692d' #@param {type: \"string\"}\n",
        "ANIME_NAME = 'Clannad' #@param {type: \"string\"}\n",
        "DOWNLOAD_DIR = '/Animpahe' #@param {type: \"string\"}\n",
        "#@markdown Keep quality 0 to download highest available quality.\n",
        "QUALITY = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "DOWNLOAD_DIR = '/drive/My Drive' + DOWNLOAD_DIR #save to drive\n",
        "print('Your video will be saved at ' + DOWNLOAD_DIR)\n",
        "print('Go to Drive: https://drive.google.com/drive/my-drive')\n",
        "\n",
        "u_time = 0\n",
        "u_t = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb7YvlE3hytt",
        "colab_type": "text"
      },
      "source": [
        "# Program code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVDR2Y0rlrJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install http.client\n",
        "!pip3 install brotli\n",
        "!sudo apt-get install ffmpeg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cL0w4mzmtQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "from http.client import HTTPSConnection\n",
        "import json\n",
        "import threading\n",
        "from google.colab import output\n",
        "from google.colab import files\n",
        "import time\n",
        "import socket, ssl, time, gzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a21dt1X-ov2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_parser(id,page):\n",
        "  conn = HTTPSConnection('animepahe.com')\n",
        "  conn.request('GET','https://animepahe.com/api?m=release&id='+id+'&l=30&sort=episode_desc&page='+page)\n",
        "  episode_json = conn.getresponse().read().decode(\"utf-8\")\n",
        "  return json.loads(episode_json)  \n",
        "\n",
        "def fetch_session(url):\n",
        "  conn = HTTPSConnection('animepahe.com')\n",
        "  anime = url.split('/')[4]\n",
        "  conn.request('GET','/anime/'+anime)\n",
        "  response = conn.getresponse()\n",
        "  page_body = response.read().decode(\"utf-8\")\n",
        "  req_index = page_body.find(\"$.getJSON('/api?\") - 1\n",
        "  id = page_body[req_index:].split('\\n')[0].split('&')[1].split('=')[1]\n",
        "  conn.request('GET','https://animepahe.com/api?m=release&id='+id+'&l=30&sort=episode_desc&page=1')\n",
        "  episode_json = conn.getresponse().read().decode(\"utf-8\")\n",
        "  episode_json = json.loads(episode_json)  \n",
        "  sessions = []\n",
        "  if 'last_page' in episode_json:\n",
        "    pages = episode_json['last_page']\n",
        "    x = 1\n",
        "    while x <= pages:\n",
        "      episode_json = list_parser(str(id),str(x))\n",
        "      for episode in episode_json['data']:\n",
        "        sessions.append([str(episode[\"episode\"]),episode[\"session\"]])\n",
        "      x=x+1\n",
        "  else:\n",
        "    for episode in episode_json['data']:\n",
        "      sessions.append([str(episode[\"episode\"]),episode[\"session\"]])\n",
        "  return (id, sessions[::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6MMh983HZqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fetch_kwik_data(id,data):\n",
        "  kwik_data = []\n",
        "  keys = []\n",
        "  data_length = len(data)\n",
        "  i = 0\n",
        "  for x in data:\n",
        "    i = i+1\n",
        "    epi = x[0]\n",
        "    video_info = fetch_video_data_as_json(id,x[1])['data']\n",
        "    for x in video_info:\n",
        "      for key in x.keys():\n",
        "        if not key in keys:\n",
        "          keys.append(key)\n",
        "        temp = [str(key),epi,x[key][\"disc\"],x[key][\"kwik\"]]\n",
        "        #print('Episode: '+epi+' Quality: '+temp[0]+'p Disc: '+temp[2]+' URL: '+temp[3])        \n",
        "        kwik_data.append(temp)\n",
        "    show_pogress(i/data_length)\n",
        "  return kwik_data, keys\n",
        "      \n",
        "def get_highest_quality(qualities):\n",
        "  highest = 0\n",
        "  for x in qualities:\n",
        "    if int(x) > highest:\n",
        "      highest = int(x)\n",
        "  return str(highest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MsJ8MSy4UuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_data_from_response(response):\n",
        "  parts = response.split(b'\\r\\n\\r\\n')\n",
        "  head = parts[0]\n",
        "  body = parts[1]\n",
        "  body = body.split(b'\\r\\n')\n",
        "  i = 0\n",
        "  refined_body = b''\n",
        "  while len(body) > i:\n",
        "    if i%2 == 1:\n",
        "      refined_body = refined_body + body[i]\n",
        "    i = i + 1\n",
        "  return (head, refined_body)\n",
        "\n",
        "def fetch_nextstream_url(URL,animepahe='https://animepahe.com/play/852a64f0-c84a-3981-0321-9d0716ab8dd5/dc27f599c18cd7c06687f6c948e530f739f51b0f3822e8c1f4b96292a9357381'):\n",
        "  import socket, ssl, brotli\n",
        "  HOST = URL.split('/')[2]\n",
        "  PATH = '/e/'+URL.split('/')[4]\n",
        "  HEADER = \"\"\"host: kwik.cx\n",
        ":authority: kwik.cx\n",
        ":method: GET\n",
        ":path: \"\"\"+PATH+\"\"\"\n",
        ":scheme: https\n",
        "accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\n",
        "accept-encoding: gzip, deflate, br\n",
        "accept-language: en-US,en;q=0.9,bn;q=0.8\n",
        "referer: \"\"\"+animepahe+\"\"\"\n",
        "sec-fetch-dest: iframe\n",
        "sec-fetch-mode: navigate\n",
        "sec-fetch-site: cross-site\n",
        "sec-fetch-user: ?1\n",
        "upgrade-insecure-requests: 1\n",
        "user-agent: Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36\n",
        "\"\"\"\n",
        "\n",
        "  HEADER.replace('\\n','\\r\\n')\n",
        "  context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n",
        "  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "  s_sock = context.wrap_socket(s, server_hostname=HOST)\n",
        "  s_sock.connect((HOST,443))\n",
        "  s_sock.send((\"GET \"+PATH+\" HTTP/1.1\\r\\n\"+HEADER+\"\\r\\n\").encode('utf-8'))\n",
        "  response = b''\n",
        "  while True:\n",
        "    data = s_sock.recv(4096)\n",
        "    response = response + data\n",
        "    if data == b'0\\r\\n\\r\\n':\n",
        "      break\n",
        "  s_sock.close()\n",
        "  parts = response.split(b'\\r\\n\\r\\n')\n",
        "  #head = parts[0]\n",
        "  body = parts[1]\n",
        "  body = body.split(b'\\r\\n')\n",
        "  i = 0\n",
        "  refined_body = b''\n",
        "  while len(body) > i:\n",
        "    if i%2 == 1:\n",
        "      refined_body = refined_body + body[i]\n",
        "    i = i + 1\n",
        "  refined_body = brotli.decompress(refined_body).decode()\n",
        "  refined_body = refined_body[refined_body.find('<script')+1:]\n",
        "  refined_body = refined_body[refined_body.find('<script')+1:]\n",
        "  refined_body = refined_body[refined_body.find('<script')+1:]\n",
        "  refined_body = refined_body[refined_body.find('<script')+1:]\n",
        "  refined_body = refined_body[refined_body.find('<script')+1:]\n",
        "  refined_body = refined_body[refined_body.find('<script')+1:]\n",
        "  x = refined_body.split('|')\n",
        "  URL ='https://' + x[128] + '-' + x[133] + '-' + x[134] + '.' + x[125] + '.' + x[136] + '/' + x[135] + '/' + x[139] + '/' + x[146] + '/' + x[148] + '.' + x[137]\n",
        "  return URL\n",
        "\n",
        "\n",
        "def fetch_m3u8(URL):\n",
        "  splits = URL.split('/')\n",
        "  HOST = splits[2]\n",
        "  PATH = '/'+splits[3]+'/'+splits[4]+'/'+splits[5]+'/'+splits[6]\n",
        "  HEADER = \"\"\":authority: \"\"\"+HOST+\"\"\"\n",
        ":method: GET\n",
        ":path: \"\"\"+PATH+\"\"\"\n",
        ":scheme: https\n",
        "accept: */*\n",
        "accept-encoding: gzip, deflate, br\n",
        "accept-language: en-US,en;q=0.9,bn;q=0.8\n",
        "cache-control: no-cache\n",
        "origin: https://kwik.cx\n",
        "pragma: no-cache\n",
        "referer: https://kwik.cx/e/O2lpweX6cBOQ\n",
        "sec-fetch-dest: empty\n",
        "sec-fetch-mode: cors\n",
        "sec-fetch-site: cross-site\n",
        "user-agent: Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36\n",
        "host: \"\"\"+HOST+\"\"\"\n",
        "\"\"\"\n",
        "  HEADER.replace('\\n','\\r\\n')\n",
        "  context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n",
        "  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "  s_sock = context.wrap_socket(s, server_hostname=HOST)\n",
        "  s_sock.connect((HOST,443))\n",
        "  s_sock.send((\"GET \"+PATH+\" HTTP/1.1\\r\\n\"+HEADER+\"\\r\\n\").encode('utf-8'))\n",
        "  response = b''\n",
        "  while True:\n",
        "    data = s_sock.recv(4096)\n",
        "    response = response + data\n",
        "    if data[len(data)-5:] == b'0\\r\\n\\r\\n':\n",
        "      break\n",
        "    if len(data) < 1:\n",
        "      break\n",
        "  s_sock.close()\n",
        "  data = extract_data_from_response(response)[1]\n",
        "  try:\n",
        "    data = gzip.decompress(data)\n",
        "  except:\n",
        "    pass\n",
        "  return data\n",
        "\n",
        "\n",
        "def fetch_ts_filename(url):\n",
        "  return url.split('/')[::-1][0]\n",
        "\n",
        "def create_file(name,data,path):\n",
        "  import os\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "  with open(path+'/'+name, 'wb') as File:\n",
        "    File.write(data)\n",
        "    File.close()\n",
        "\n",
        "def fetch_key_url(line):\n",
        "  line = line.split(b'=')[2]\n",
        "  return line[1:len(line)-1].decode()\n",
        "\n",
        "def fetch_key(url):\n",
        "  return fetch_ts(url)  \n",
        "\n",
        "def fetch_ts(URL):\n",
        "  tc = time.time()\n",
        "  global u_time\n",
        "  splits = URL.split('/')\n",
        "  HOST = splits[2]\n",
        "  PATH = '/'+splits[3]+'/'+splits[4]+'/'+splits[5]+'/'+splits[6]\n",
        "  HEADER = \"\"\":authority: \"\"\"+HOST+\"\"\"\n",
        ":method: GET\n",
        ":path: /stream/0000/8a708bf4d0fcfabf96f912072b4b37e2482c6cfb021e20122fcfa551e0390710/uwu.m3u8\n",
        ":scheme: https\n",
        "accept: */*\n",
        "accept-encoding: gzip, deflate, br\n",
        "accept-language: en-US,en;q=0.9,bn;q=0.8\n",
        "cache-control: no-cache\n",
        "origin: https://kwik.cx\n",
        "pragma: no-cache\n",
        "referer: https://kwik.cx/e/O2lpweX6cBOQ\n",
        "sec-fetch-dest: empty\n",
        "sec-fetch-mode: cors\n",
        "sec-fetch-site: cross-site\n",
        "user-agent: Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36\n",
        "host: \"\"\"+HOST+\"\"\"\n",
        "\"\"\"\n",
        "  HEADER.replace('\\n','\\r\\n')\n",
        "  context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n",
        "  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "  s_sock = context.wrap_socket(s, server_hostname=HOST)  \n",
        "  s_sock.connect((HOST,443))  \n",
        "  s_sock.send((\"GET \"+PATH+\" HTTP/1.1\\r\\n\"+HEADER+\"\\r\\n\").encode('utf-8'))\n",
        "  response = b''\n",
        "  tc = time.time() - tc\n",
        "  while True:\n",
        "    t = time.time()\n",
        "    data = s_sock.recv(4096) \n",
        "    u_time = ((time.time() - t + tc) * 4096/len(data) + u_time)/2\n",
        "    response = response + data    \n",
        "    if response.find(b'Content-Length') != -1 and response.find(b'\\r\\n\\r\\n') != -1:\n",
        "      body_length = int(response[response.find(b'Content-Length'):].split(b'\\r\\n')[0].split(b' ')[1])\n",
        "      if body_length == len(response.split(b'\\r\\n\\r\\n')[1]):\n",
        "        break\n",
        "    if len(data) < 1:\n",
        "      break     \n",
        "  s_sock.close()\n",
        "  return response.split(b'\\r\\n\\r\\n')[1]\n",
        "\n",
        "\n",
        "def show_pogress(pogress, length=30):\n",
        "  import sys  \n",
        "  sys.stdout.flush()\n",
        "  percentage = pogress*100\n",
        "  pogress = int(pogress*length)\n",
        "  sys.stdout.write('\\rPogress: ['+'='*pogress+' '*(length-pogress)+'] '+str(int(percentage))+'%  ')\n",
        "\n",
        "\n",
        "def show_ts_pogress(pogress, length=30):\n",
        "  import sys\n",
        "  global u_time\n",
        "  sys.stdout.flush()\n",
        "  try:\n",
        "    speed = str(int(50/u_time)/100) + ' mbps'\n",
        "  except:\n",
        "    speed = '??? mbps'\n",
        "  percentage = pogress*100\n",
        "  pogress = int(pogress*length)\n",
        "  sys.stdout.write('\\rPogress: ['+'='*pogress+' '*(length-pogress)+'] '+str(int(percentage))+'%  '+speed)\n",
        "\n",
        "\n",
        "def fetch_and_write_video_raw(url, path='/content'):\n",
        "  import os\n",
        "  kwik = url\n",
        "  path = path\n",
        "  data = fetch_m3u8(fetch_nextstream_url(kwik)).split(b'\\n')\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "  with open(path+'/uwu.m3u8', 'wb') as m3u8:\n",
        "    i = 0\n",
        "    data_length = len(data)\n",
        "    while i < data_length:\n",
        "      line = data[i]     \n",
        "\n",
        "      if line.find(b'#EXT-X-KEY') != -1:\n",
        "        url = fetch_key_url(line)\n",
        "        create_file('mon.key',fetch_key(url),path)\n",
        "        line = line.replace(url.encode(), 'mon.key'.encode())\n",
        "      if line.find(b'https') == 0:\n",
        "        url = line[line.find(b'https'):].decode()\n",
        "        file_name = fetch_ts_filename(url)      \n",
        "        create_file(file_name,fetch_ts(url),path)\n",
        "        line = line.replace(url.encode(), file_name.encode())   \n",
        "      m3u8.write(line+b'\\n')\n",
        "      show_ts_pogress((i+1)/data_length)\n",
        "      i = i+1\n",
        "    m3u8.close()\n",
        "    print('\\n')\n",
        "\n",
        "def convert_to_mp4(file_path,download_path):\n",
        "  return subprocess.call(['ffmpeg', '-allowed_extensions', 'ALL', '-i', file_path, '-c', 'copy', '-bsf:a', 'aac_adtstoasc', download_path])\n",
        "\n",
        "\n",
        "\n",
        "def fetch_video_data_as_json(id,session):\n",
        "  conn = HTTPSConnection('animepahe.com')\n",
        "  conn.request('GET', '/api?m=links&id='+id+'&session='+session+'&p=kwik')\n",
        "  response = conn.getresponse()\n",
        "  return json.loads(response.read().decode('utf-8'))\n",
        "\n",
        "def downloader(x,path):\n",
        "  try:\n",
        "    fetch_and_write_video_raw(x[3],path)\n",
        "  except:\n",
        "    try:\n",
        "      fetch_and_write_video_raw(x[3],path)\n",
        "    except:\n",
        "      try:\n",
        "        fetch_and_write_video_raw(x[3],path)\n",
        "      except:\n",
        "        try:\n",
        "          fetch_and_write_video_raw(x[3],path)\n",
        "        except Exception as e:\n",
        "          print('UNABLE TO FETCH EPISODE: '+x[1])\n",
        "          print(e)\n",
        "\n",
        "def clear_session():\n",
        "  if os.path.exists(SESSION):\n",
        "    os.remove(SESSION)\n",
        "  \n",
        "def clear():\n",
        "  output.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etfl8oRmiQVK",
        "colab_type": "text"
      },
      "source": [
        "# Status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nti8mphD4qD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEMP_DIR = '/content/animpahe_downloader_cache'\n",
        "ANIME_NAME = ANIME_NAME.replace(' ','_')\n",
        "SESSION = DOWNLOAD_DIR+'/'+ANIME_NAME+'/session.data'\n",
        "if not os.path.exists(SESSION):\n",
        "  print('Creating new session'+SESSION)\n",
        "  file_name = SESSION.split('/')[::-1][0]\n",
        "  path = SESSION.replace('/'+file_name,'')\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "  open(SESSION,'w+').close()\n",
        "  \n",
        "session = []\n",
        "session_reader = open(SESSION,'r')\n",
        "sessions = session_reader.read()\n",
        "if sessions != '':\n",
        "  session = sessions.split('\\n')\n",
        "session_reader.close()\n",
        "quality = ''\n",
        "\n",
        "if not QUALITY == 0:\n",
        "  quality = str(QUALITY)\n",
        "\n",
        "threads = []\n",
        "\n",
        "print('FETCHING FROM: '+URL)\n",
        "id, data = fetch_session(URL)\n",
        "\n",
        "print('FETCHING EPISODE LIST:')\n",
        "data, qualities= fetch_kwik_data(id,data)\n",
        "\n",
        "if quality == '':\n",
        "  quality = get_highest_quality(qualities)\n",
        "\n",
        "print(\"TARGET QUALITY: \"+quality+'p')\n",
        "\n",
        "\n",
        "\n",
        "for x in data:\n",
        "  if x[0] == quality and not x[3] in session:\n",
        "    path = DOWNLOAD_DIR+'/'+ANIME_NAME+'/'+ANIME_NAME+'_'+x[2]+'_'+x[3].split('/')[::-1][0]+'_e'+x[1]+'_'+x[0]+'p.mp4'\n",
        "    temp_path = TEMP_DIR+'/'+ANIME_NAME+x[2]+'/e'+x[1]+'_'+x[0]+'p'+x[3].split('/')[::-1][0]\n",
        "    print('DOWNLOADING EPISODE: ' + x[1])\n",
        "    print('PATH: '+path)\n",
        "    downloader(x, temp_path)\n",
        "    convert_to_mp4(temp_path+'/uwu.m3u8',path) \n",
        "    with open(SESSION,'a') as session_writer:\n",
        "      session_writer.write(x[3]+'\\n')\n",
        "      session_writer.close()\n",
        "    clear()\n",
        "\n",
        "print('Download complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDeudcrNiVTa",
        "colab_type": "text"
      },
      "source": [
        "# Clear session\n",
        "\n",
        "Clear the session if you want to redownload the series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RinACmXJ2Zao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}